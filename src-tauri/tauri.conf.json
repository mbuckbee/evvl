{
  "$schema": "../node_modules/@tauri-apps/cli/config.schema.json",
  "productName": "Evvl",
  "version": "0.1.9",
  "identifier": "com.evvl.app",
  "build": {
    "frontendDist": "../out",
    "devUrl": "http://localhost:3333",
    "beforeDevCommand": "npm run dev",
    "beforeBuildCommand": "npm run build:tauri"
  },
  "app": {
    "withGlobalTauri": true,
    "windows": [
      {
        "title": "Evvl",
        "width": 1400,
        "height": 900,
        "minWidth": 1000,
        "minHeight": 700,
        "resizable": true,
        "fullscreen": false
      }
    ],
    "security": {
      "csp": null
    }
  },
  "bundle": {
    "active": true,
    "targets": "all",
    "icon": [
      "icons/32x32.png",
      "icons/128x128.png",
      "icons/128x128@2x.png",
      "icons/icon.icns",
      "icons/icon.ico"
    ],
    "macOS": {
      "signingIdentity": null,
      "hardenedRuntime": true
    },
    "createUpdaterArtifacts": true
  },
  "plugins": {
    "updater": {
      "endpoints": [
        "https://app.evvl.ai/api/updates/check"
      ],
      "pubkey": "dW50cnVzdGVkIGNvbW1lbnQ6IG1pbmlzaWduIHB1YmxpYyBrZXk6IDI2REVENjI2QUMzOTA3QzAKUldUQUJ6bXNKdGJlSnJzcXlpejBCWmYrSXZPMHY3LzdnQ0JaSjFrYVZNSmw4ZnR0MG9qdlg0NHAK"
    },
    "cli": {
      "description": "Evvl - AI Model Evaluation CLI",
      "longDescription": "Evvl CLI enables programmatic use of AI model evaluations from the command line.",
      "args": [
        {
          "name": "prompt",
          "description": "Prompt text to evaluate",
          "takesValue": true,
          "index": 1,
          "multiple": true
        },
        {
          "name": "help",
          "short": "h",
          "description": "Print help information",
          "takesValue": false
        },
        {
          "name": "version",
          "short": "v",
          "description": "Print version information",
          "takesValue": false
        },
        {
          "name": "settings",
          "description": "Open settings page",
          "takesValue": false
        },
        {
          "name": "open",
          "short": "o",
          "description": "Open GUI to show results",
          "takesValue": false
        },
        {
          "name": "json",
          "description": "Output as JSON (default when piped)",
          "takesValue": false
        },
        {
          "name": "project",
          "short": "p",
          "description": "Project name or ID",
          "takesValue": true
        }
      ],
      "subcommands": {
        "run": {
          "description": "Run an evaluation",
          "args": [
            {
              "name": "prompt",
              "description": "Prompt text to evaluate (or new version content with --prompt-name)",
              "takesValue": true
            },
            {
              "name": "prompt-name",
              "description": "Name of saved prompt to use (or create new version for)",
              "takesValue": true
            },
            {
              "name": "version-note",
              "description": "Note for the new version (auto-saved if prompt differs)",
              "takesValue": true
            },
            {
              "name": "models",
              "short": "m",
              "description": "Comma-separated list of models (omit to use project's model configs)",
              "takesValue": true
            },
            {
              "name": "dataset",
              "short": "d",
              "description": "Dataset name for batch evaluation (omit to use project's first dataset)",
              "takesValue": true
            },
            {
              "name": "no-dataset",
              "description": "Don't use any dataset even if project has one",
              "takesValue": false
            }
          ]
        },
        "projects": {
          "description": "List all projects",
          "args": []
        },
        "prompts": {
          "description": "List or test prompts",
          "subcommands": {
            "list": {
              "description": "List all prompts in a project",
              "args": []
            },
            "test": {
              "description": "Test a specific prompt version",
              "args": [
                {
                  "name": "name",
                  "description": "Prompt name to test",
                  "takesValue": true,
                  "index": 1
                }
              ]
            }
          }
        },
        "export": {
          "description": "Export evaluation results",
          "args": [
            {
              "name": "run",
              "short": "r",
              "description": "Evaluation run ID to export",
              "takesValue": true
            },
            {
              "name": "format",
              "short": "f",
              "description": "Export format: json or csv",
              "takesValue": true
            }
          ]
        }
      }
    }
  }
}
